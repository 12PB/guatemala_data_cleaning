{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858416a0",
   "metadata": {},
   "source": [
    "## 0: Save intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1953fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04131f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('HOGARES.DTA', ['region', 'area', 'hogar', 'thogar', 'factor']), ('AUTOIDH.DTA', ['hogar', 'idenho_1', 'getnicoh']), ('ECV02H01.DTA', ['hogar', 'item', 'p01b04a', 'p01b04b', 'p01b04c']), ('CONSUMO5.DTA', ['depto', 'mupio', 'sector', 'hogar', 'upm2', 'agreg3']), ('ECV18N15.DTA', ['hogar', 'p15b01', 'p15b02']), ('ECV21A16.DTA', ['hogar', 'tipo', 'tcuerda', 'p16a07a', 'p16a07b']), ('ECV31A16.DTA', ['hogar', 'tipo', 'item', 'p16j02', 'p16j03']), ('ECV17E14.DTA', ['hogar', 'tipo', 'item', 'p14a01', 'p14a02']), ('ECV09P05.DTA', ['hogar', 'caso', 'sexo', 'edad', 'p05a02', 'p05a03', 'p05b05', 'p07b01', 'p07b06b', 'p07b29']), ('ECV28A16.DTA', ['hogar', 'tipo', 'item', 'p16g01', 'p16g02']), ('ECV01H01.DTA', ['hogar', 'p01a01', 'p01a02', 'p01a03', 'p01a04', 'p01a05a', 'p01a05b', 'p01a05c', 'p01a05d', 'p01a05e', 'p01a05f', 'p01a06', 'p01a07', 'p01a08', 'p01a09', 'p01a10', 'p01a11', 'p01a12', 'p01a13', 'p01a14', 'p01a23', 'p01a25', 'p01a26', 'p01a34', 'p01a35', 'p01a39', 'p01a44', 'p01a45', 'p01c01']), ('ECV19N15.DTA', ['hogar', 'p15b04']), ('ECOM03.DTA', ['depto', 'mupio', 'sector', 'c02b01', 'c02b02a', 'c02b02b']), ('ECV11P10.DTA', ['hogar', 'caso', 'p10d01', 'p10d03', 'p10d04', 'p10d06', 'p10e05a']), ('ECOM02.DTA', ['depto', 'mupio', 'sector', 'c02act', 'c02a01'])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in metadata\n",
    "field_selection_path = '../metadata/guatemala_variable_filtered_v4.csv'\n",
    "field_df = pd.read_csv(field_selection_path)\n",
    "\n",
    "# Include only selected variables\n",
    "included_df = field_df[field_df['included'].str.lower() == 'yes']\n",
    "\n",
    "# Create mapping diictionary between modules and associated variables\n",
    "module_var_map = defaultdict(list)\n",
    "for _, row in included_df.iterrows():\n",
    "    module_name = row['module'].strip().upper()\n",
    "    variable_name = row['variable_name'].strip()\n",
    "    module_var_map[module_name].append(variable_name)\n",
    "\n",
    "module_var_map.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b7cadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HOGARES.DTA with 5 variables.\n",
      "Loaded AUTOIDH.DTA with 3 variables.\n",
      "Loaded ECV02H01.DTA with 5 variables.\n",
      "Loaded CONSUMO5.DTA with 6 variables.\n",
      "Loaded ECV18N15.DTA with 3 variables.\n",
      "Loaded ECV21A16.DTA with 5 variables.\n",
      "Loaded ECV31A16.DTA with 5 variables.\n",
      "Loaded ECV17E14.DTA with 5 variables.\n",
      "Loaded ECV09P05.DTA with 10 variables.\n",
      "Loaded ECV28A16.DTA with 5 variables.\n",
      "Loaded ECV01H01.DTA with 29 variables.\n",
      "Loaded ECV19N15.DTA with 2 variables.\n",
      "Loaded ECOM03.DTA with 6 variables.\n",
      "Loaded ECV11P10.DTA with 7 variables.\n",
      "Loaded ECOM02.DTA with 5 variables.\n"
     ]
    }
   ],
   "source": [
    "# Read the corresponding fields of each module\n",
    "dataframes = {} \n",
    "raw_data_path = '../raw_data_downloaded'\n",
    "\n",
    "for module_file, var_list in module_var_map.items():\n",
    "\n",
    "    module_path = os.path.join(raw_data_path, module_file)\n",
    "    \n",
    "    if not os.path.exists(module_path):\n",
    "        print(f\"Warning: {module_file} not found in raw_data/\")\n",
    "        continue\n",
    "    \n",
    "    # Read modules in old stata format using pd.read_stata\n",
    "    if module_file in ['ECOM02.DTA','ECOM03.DTA']:\n",
    "        df = pd.read_stata(module_path, columns=var_list, convert_categoricals=True)\n",
    "    else: # Read modules in stata version 110 (not supported by read_stata, use pyreadstat)\n",
    "        df, meta = pyreadstat.read_dta(module_path, usecols=var_list, apply_value_formats=True, encoding='iso-8859-1')\n",
    "\n",
    "    # Rename hhid \n",
    "    if 'hogar' in df.columns:\n",
    "        df['hogar'] = df['hogar'].astype(str)\n",
    "        df.rename(columns={'hogar': 'hhid'}, inplace=True)\n",
    "\n",
    "    \"\"\" \n",
    "    # Check type of \n",
    "    if 'caso' in df.columns:\n",
    "        df['caso'] = df['caso'].astype(str)\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframes[module_file] = df\n",
    "    print(f\"Loaded {module_file} with {len(var_list)} variables.\")\n",
    "\n",
    "output_path = '../intermediate_data'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for module_file, df in dataframes.items():\n",
    "    csv_name = module_file.replace('.DTA', '.csv')\n",
    "    df.to_csv(os.path.join(output_path, csv_name), index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a668e",
   "metadata": {},
   "source": [
    "## 1: Clean ```HOGARES``` - Main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce49a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing report: \n",
      "region    0\n",
      "area      0\n",
      "hhid      0\n",
      "thogar    0\n",
      "factor    0\n",
      "dtype: int64\n",
      "\n",
      "Data Types: \n",
      "region           category\n",
      "area             category\n",
      "hhid       string[python]\n",
      "hh_size           float64\n",
      "hh_wgt            float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>area</th>\n",
       "      <th>hhid</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>hh_wgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metropolitana</td>\n",
       "      <td>urbana</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metropolitana</td>\n",
       "      <td>urbana</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metropolitana</td>\n",
       "      <td>urbana</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>metropolitana</td>\n",
       "      <td>urbana</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>metropolitana</td>\n",
       "      <td>urbana</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>suroriente</td>\n",
       "      <td>rural</td>\n",
       "      <td>7272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>suroriente</td>\n",
       "      <td>rural</td>\n",
       "      <td>7273</td>\n",
       "      <td>5.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>suroriente</td>\n",
       "      <td>rural</td>\n",
       "      <td>7274</td>\n",
       "      <td>7.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>suroriente</td>\n",
       "      <td>rural</td>\n",
       "      <td>7275</td>\n",
       "      <td>6.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>suroriente</td>\n",
       "      <td>rural</td>\n",
       "      <td>7276</td>\n",
       "      <td>10.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7276 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             region    area  hhid  hh_size  hh_wgt\n",
       "0     metropolitana  urbana     1      4.0   541.0\n",
       "1     metropolitana  urbana     2      3.0   541.0\n",
       "2     metropolitana  urbana     3      6.0   541.0\n",
       "3     metropolitana  urbana     4      1.0   541.0\n",
       "4     metropolitana  urbana     5      3.0   541.0\n",
       "...             ...     ...   ...      ...     ...\n",
       "7271     suroriente   rural  7272      1.0   219.0\n",
       "7272     suroriente   rural  7273      5.0   219.0\n",
       "7273     suroriente   rural  7274      7.0   219.0\n",
       "7274     suroriente   rural  7275      6.0   219.0\n",
       "7275     suroriente   rural  7276     10.0   219.0\n",
       "\n",
       "[7276 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hogares = pd.read_csv('../intermediate_data/HOGARES.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Check for missing data\n",
    "missing_report = hogares.isnull().sum()\n",
    "print('Missing report: ')\n",
    "print(missing_report)\n",
    "\n",
    "# Rename columns \n",
    "hogares = hogares.rename(columns={'factor': 'hh_wgt', 'thogar': 'hh_size'})\n",
    "\n",
    "# Convert data types\n",
    "hogares['hhid'] = hogares['hhid'].astype('int64').astype('string')\n",
    "hogares['region'] = hogares['region'].astype('category')\n",
    "hogares['area'] = hogares['area'].astype('category')\n",
    "\n",
    "# save csv\n",
    "hogares.to_csv('../cleaned_data/HOGARES_cleaned.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print('\\nData Types: ')\n",
    "print(hogares.dtypes)\n",
    "\n",
    "hogares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407c0c3",
   "metadata": {},
   "source": [
    "## 2. Clean ```AUTOIDH``` - Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c09e5e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing report: \n",
      "hhid        0\n",
      "idenho_1    0\n",
      "getnicoh    0\n",
      "dtype: int64\n",
      "\n",
      "Data Types: \n",
      "hhid           int64\n",
      "idenho_1    category\n",
      "getnicoh    category\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhid</th>\n",
       "      <th>idenho_1</th>\n",
       "      <th>getnicoh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Otro Maya</td>\n",
       "      <td>Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>7272</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>7273</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>7274</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>7275</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>7276</td>\n",
       "      <td>No indigena</td>\n",
       "      <td>No Indigenas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7276 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hhid     idenho_1      getnicoh\n",
       "0        1    Otro Maya     Indigenas\n",
       "1        2  No indigena  No Indigenas\n",
       "2        3  No indigena  No Indigenas\n",
       "3        4  No indigena  No Indigenas\n",
       "4        5  No indigena  No Indigenas\n",
       "...    ...          ...           ...\n",
       "7271  7272  No indigena  No Indigenas\n",
       "7272  7273  No indigena  No Indigenas\n",
       "7273  7274  No indigena  No Indigenas\n",
       "7274  7275  No indigena  No Indigenas\n",
       "7275  7276  No indigena  No Indigenas\n",
       "\n",
       "[7276 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoidh = pd.read_csv('../intermediate_data/AUTOIDH.csv', encoding='utf-8-sig')\n",
    "missing_report = autoidh.isnull().sum()\n",
    "\n",
    "print(\"Missing report: \")\n",
    "print(missing_report)\n",
    "\n",
    "autoidh['idenho_1'] = autoidh['idenho_1'].astype('category')\n",
    "autoidh['getnicoh'] = autoidh['getnicoh'].astype('category')\n",
    "\n",
    "# save csv\n",
    "autoidh.to_csv('../cleaned_data/AUTOIDH_cleaned.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print('\\nData Types: ')\n",
    "print(autoidh.dtypes)\n",
    "\n",
    "autoidh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a57957",
   "metadata": {},
   "source": [
    "## 3. Clean ```CONSUMO5``` - Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d583009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing report: \n",
      "depto     0\n",
      "mupio     0\n",
      "sector    0\n",
      "hhid      0\n",
      "upm2      0\n",
      "agreg3    0\n",
      "dtype: int64\n",
      "\n",
      "Data Types: \n",
      "depto                                   category\n",
      "mupio                                   category\n",
      "sector                                  category\n",
      "hhid                              string[python]\n",
      "upm2                                     float64\n",
      "consumption_per_capita_per_day           float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depto</th>\n",
       "      <th>mupio</th>\n",
       "      <th>sector</th>\n",
       "      <th>hhid</th>\n",
       "      <th>upm2</th>\n",
       "      <th>consumption_per_capita_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guatemala</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1031003.0</td>\n",
       "      <td>22.024104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guatemala</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1031003.0</td>\n",
       "      <td>20.392536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guatemala</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1031003.0</td>\n",
       "      <td>21.341869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guatemala</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1031003.0</td>\n",
       "      <td>112.619080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guatemala</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1031003.0</td>\n",
       "      <td>61.555193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7272</td>\n",
       "      <td>22132008.0</td>\n",
       "      <td>13.389319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7273</td>\n",
       "      <td>22132008.0</td>\n",
       "      <td>4.574897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7274</td>\n",
       "      <td>22132008.0</td>\n",
       "      <td>3.830335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7275</td>\n",
       "      <td>22132008.0</td>\n",
       "      <td>4.126309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7276</td>\n",
       "      <td>22132008.0</td>\n",
       "      <td>3.628737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7276 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          depto mupio sector  hhid        upm2  consumption_per_capita_per_day\n",
       "0     guatemala   3.0    3.0     1   1031003.0                       22.024104\n",
       "1     guatemala   3.0    3.0     2   1031003.0                       20.392536\n",
       "2     guatemala   3.0    3.0     3   1031003.0                       21.341869\n",
       "3     guatemala   3.0    3.0     4   1031003.0                      112.619080\n",
       "4     guatemala   3.0    3.0     5   1031003.0                       61.555193\n",
       "...         ...   ...    ...   ...         ...                             ...\n",
       "7271    jutiapa  13.0    7.0  7272  22132008.0                       13.389319\n",
       "7272    jutiapa  13.0    7.0  7273  22132008.0                        4.574897\n",
       "7273    jutiapa  13.0    7.0  7274  22132008.0                        3.830335\n",
       "7274    jutiapa  13.0    7.0  7275  22132008.0                        4.126309\n",
       "7275    jutiapa  13.0    7.0  7276  22132008.0                        3.628737\n",
       "\n",
       "[7276 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumo5 = pd.read_csv('../intermediate_data/CONSUMO5.csv', encoding='utf-8-sig')\n",
    "\n",
    "missing_report = consumo5.isnull().sum()\n",
    "print(\"Missing report: \")\n",
    "print(missing_report)\n",
    "\n",
    "# make agreg3 to be per capita per day in 2017 USD PPP\n",
    "conversion_factor = 0.6878405536 \n",
    "consumo5['consumption_per_capita_per_day'] = (consumo5['agreg3'] / 365) * conversion_factor\n",
    "\n",
    "consumo5['hhid'] = consumo5['hhid'].astype('Int64').astype('string')\n",
    "\n",
    "for col in ['mupio', 'sector', 'depto']:\n",
    "    consumo5[col] = consumo5[col].astype('category')\n",
    "\n",
    "consumo5.drop(columns = ['agreg3'], inplace = True)\n",
    "\n",
    "consumo5.to_csv('../cleaned_data/CONSUMO5_cleaned.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print('\\nData Types: ')\n",
    "print(consumo5.dtypes)\n",
    "\n",
    "consumo5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd04768",
   "metadata": {},
   "source": [
    "## 4. Clean ```ECV01H01``` - Housing characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5287b290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial missing report:\n",
      "p01a11      47\n",
      "p01a13    2185\n",
      "p01a14    2185\n",
      "p01a35    1975\n",
      "p01a44    3019\n",
      "p01a45    3019\n",
      "dtype: int64\n",
      "\n",
      "Final missing report:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Data Types: \n",
      "hhid       string[python]\n",
      "p01a01           category\n",
      "p01a02           category\n",
      "p01a03           category\n",
      "p01a04           category\n",
      "p01a05a          category\n",
      "p01a05b          category\n",
      "p01a05c          category\n",
      "p01a05d          category\n",
      "p01a05e          category\n",
      "p01a05f          category\n",
      "p01a06              Int64\n",
      "p01a07              Int64\n",
      "p01a08              Int64\n",
      "p01a09              Int64\n",
      "p01a10           category\n",
      "p01a11           category\n",
      "p01a12           category\n",
      "p01a13           category\n",
      "p01a14           category\n",
      "p01a23           category\n",
      "p01a25           category\n",
      "p01a26           category\n",
      "p01a34           category\n",
      "p01a35           category\n",
      "p01a39           category\n",
      "p01a44           category\n",
      "p01a45           category\n",
      "p01c01           category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ecv01h01 = pd.read_csv('../intermediate_data/ECV01H01.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Check for columns with missing info\n",
    "missing_report = ecv01h01.isnull().sum()\n",
    "missing_col = missing_report[missing_report > 0].index.tolist()\n",
    "print(\"Initial missing report:\")\n",
    "print(missing_report[missing_report > 0])\n",
    "\n",
    "# Amend dtype hhid\n",
    "ecv01h01['hhid'] = ecv01h01['hhid'].astype('Int64').astype('string')\n",
    "\n",
    "# Since all columns with missing info are categorical,\n",
    "# set as categorical dtype, add missing as category\n",
    "for col in missing_col:\n",
    "    ecv01h01[col] = ecv01h01[col].astype('category').cat.add_categories('missing').fillna('missing')\n",
    "\n",
    "# Set type of numeric columns\n",
    "int_cols = ['p01a06', 'p01a07', 'p01a08', 'p01a09']\n",
    "for col in int_cols:\n",
    "    ecv01h01[col] = ecv01h01[col].astype('Int64')\n",
    "\n",
    "# Get all categorical columns and set as category dtype\n",
    "cat_cols = list(set(ecv01h01.columns) - set(['hhid']) - set(missing_col) - set(int_cols))\n",
    "for col in cat_cols:\n",
    "    ecv01h01[col] = ecv01h01[col].astype('category')\n",
    "\n",
    "ecv01h01.to_csv('../cleaned_data/ECV01H01_cleaned.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\nFinal missing report:\")\n",
    "missing_report = ecv01h01.isnull().sum()\n",
    "print(missing_report[missing_report > 0])\n",
    "\n",
    "print('\\nData Types: ')\n",
    "print(ecv01h01.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ed655",
   "metadata": {},
   "source": [
    "## 5. Clean ```ECV02H01``` - Energy Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a146ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial missing report: \n",
      "p01b04a    31593\n",
      "p01b04b    31593\n",
      "p01b04c    31593\n",
      "dtype: int64\n",
      "\n",
      "Final missing report:\n",
      "Series([], dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhid</th>\n",
       "      <th>item</th>\n",
       "      <th>p01b04a</th>\n",
       "      <th>p01b04b</th>\n",
       "      <th>p01b04c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>candelas y/o veladoras</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>kerosene (gas corriente)</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>gas propano</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>carbon</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>baterias</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58203</th>\n",
       "      <td>7276.0</td>\n",
       "      <td>carbon</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58204</th>\n",
       "      <td>7276.0</td>\n",
       "      <td>baterias</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58205</th>\n",
       "      <td>7276.0</td>\n",
       "      <td>electricidad</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58206</th>\n",
       "      <td>7276.0</td>\n",
       "      <td>leÑa o palos</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58207</th>\n",
       "      <td>7276.0</td>\n",
       "      <td>otra fuente de energia</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58208 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hhid                      item  p01b04a  p01b04b  p01b04c\n",
       "0         1.0    candelas y/o veladoras  missing  missing  missing\n",
       "1         1.0  kerosene (gas corriente)  missing  missing  missing\n",
       "2         1.0               gas propano       si       no       no\n",
       "3         1.0                    carbon  missing  missing  missing\n",
       "4         1.0                  baterias       si       si       no\n",
       "...       ...                       ...      ...      ...      ...\n",
       "58203  7276.0                    carbon  missing  missing  missing\n",
       "58204  7276.0                  baterias       si       si       no\n",
       "58205  7276.0              electricidad  missing  missing  missing\n",
       "58206  7276.0              leÑa o palos       si       no       no\n",
       "58207  7276.0    otra fuente de energia  missing  missing  missing\n",
       "\n",
       "[58208 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecv02h01 = pd.read_csv('../intermediate_data/ECV02H01.csv', encoding='utf-8-sig')\n",
    "\n",
    "missing_report = ecv02h01.isnull().sum()\n",
    "print(\"Initial missing report: \")\n",
    "print(missing_report[missing_report > 0])\n",
    "\n",
    "# Step 1: Translating labels\n",
    "energy_translation = {\n",
    "    \"candelas y/o veladoras\": \"candles\",\n",
    "    \"kerosene (gas corriente)\": \"kerosene\",\n",
    "    \"gas propano\": \"propane_gas\",\n",
    "    \"carbon\": \"charcoal\",\n",
    "    \"baterias\": \"batteries\",\n",
    "    \"electricidad\": \"electricity\",\n",
    "    \"leña o palos\": \"firewood\",\n",
    "    \"otra fuente de energia\": \"other_energy\"\n",
    "}\n",
    "\n",
    "use_map = {\n",
    "    'p01b04a': 'household',\n",
    "    'p01b04b': 'cooking',\n",
    "    'p01b04c': 'home_business',\n",
    "    #'p01b04d': 'other'\n",
    "}\n",
    "\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "for col in use_map.keys():\n",
    "    ecv02h01[col] = ecv02h01[col].fillna('missing')\n",
    "\n",
    "print(\"\\nFinal missing report:\")\n",
    "missing_report = ecv01h01.isnull().sum()\n",
    "print(missing_report[missing_report > 0])\n",
    "\n",
    "ecv02h01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07df38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types: \n",
      "final_col\n",
      "hhid                          string[python]\n",
      "batteries_cooking                     object\n",
      "batteries_home_business               object\n",
      "batteries_household                   object\n",
      "candles_cooking                       object\n",
      "candles_home_business                 object\n",
      "candles_household                     object\n",
      "charcoal_cooking                      object\n",
      "charcoal_home_business                object\n",
      "charcoal_household                    object\n",
      "electricity_cooking                   object\n",
      "electricity_home_business             object\n",
      "electricity_household                 object\n",
      "kerosene_cooking                      object\n",
      "kerosene_home_business                object\n",
      "kerosene_household                    object\n",
      "other_energy_cooking                  object\n",
      "other_energy_home_business            object\n",
      "other_energy_household                object\n",
      "propane_gas_cooking                   object\n",
      "propane_gas_home_business             object\n",
      "propane_gas_household                 object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>final_col</th>\n",
       "      <th>hhid</th>\n",
       "      <th>batteries_cooking</th>\n",
       "      <th>batteries_home_business</th>\n",
       "      <th>batteries_household</th>\n",
       "      <th>candles_cooking</th>\n",
       "      <th>candles_home_business</th>\n",
       "      <th>candles_household</th>\n",
       "      <th>charcoal_cooking</th>\n",
       "      <th>charcoal_home_business</th>\n",
       "      <th>charcoal_household</th>\n",
       "      <th>...</th>\n",
       "      <th>electricity_household</th>\n",
       "      <th>kerosene_cooking</th>\n",
       "      <th>kerosene_home_business</th>\n",
       "      <th>kerosene_household</th>\n",
       "      <th>other_energy_cooking</th>\n",
       "      <th>other_energy_home_business</th>\n",
       "      <th>other_energy_household</th>\n",
       "      <th>propane_gas_cooking</th>\n",
       "      <th>propane_gas_home_business</th>\n",
       "      <th>propane_gas_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>...</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>...</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>...</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>...</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>...</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>7272</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>7273</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>7274</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>7275</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>7276</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>si</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7276 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "final_col  hhid batteries_cooking batteries_home_business batteries_household  \\\n",
       "0             1                si                      no                  si   \n",
       "1             2           missing                 missing             missing   \n",
       "2             3                no                      no                  si   \n",
       "3             4           missing                 missing             missing   \n",
       "4             5                no                      no                  si   \n",
       "...         ...               ...                     ...                 ...   \n",
       "7271       7272                si                      no                  si   \n",
       "7272       7273                si                      no                  si   \n",
       "7273       7274                no                      no                  si   \n",
       "7274       7275                no                      no                  si   \n",
       "7275       7276                si                      no                  si   \n",
       "\n",
       "final_col candles_cooking candles_home_business candles_household  \\\n",
       "0                 missing               missing           missing   \n",
       "1                 missing               missing           missing   \n",
       "2                 missing               missing           missing   \n",
       "3                 missing               missing           missing   \n",
       "4                      no                    si                no   \n",
       "...                   ...                   ...               ...   \n",
       "7271              missing               missing           missing   \n",
       "7272              missing               missing           missing   \n",
       "7273                   no                    no                si   \n",
       "7274                   no                    no                si   \n",
       "7275                   no                    no                si   \n",
       "\n",
       "final_col charcoal_cooking charcoal_home_business charcoal_household  ...  \\\n",
       "0                  missing                missing            missing  ...   \n",
       "1                  missing                missing            missing  ...   \n",
       "2                       no                     no                 si  ...   \n",
       "3                  missing                missing            missing  ...   \n",
       "4                       no                     no                 si  ...   \n",
       "...                    ...                    ...                ...  ...   \n",
       "7271               missing                missing            missing  ...   \n",
       "7272               missing                missing            missing  ...   \n",
       "7273               missing                missing            missing  ...   \n",
       "7274               missing                missing            missing  ...   \n",
       "7275               missing                missing            missing  ...   \n",
       "\n",
       "final_col electricity_household kerosene_cooking kerosene_home_business  \\\n",
       "0                            si          missing                missing   \n",
       "1                            si          missing                missing   \n",
       "2                            si          missing                missing   \n",
       "3                            si          missing                missing   \n",
       "4                            si          missing                missing   \n",
       "...                         ...              ...                    ...   \n",
       "7271                    missing               no                     no   \n",
       "7272                    missing               no                     no   \n",
       "7273                    missing               no                     no   \n",
       "7274                    missing               no                     no   \n",
       "7275                    missing               no                     no   \n",
       "\n",
       "final_col kerosene_household other_energy_cooking other_energy_home_business  \\\n",
       "0                    missing              missing                    missing   \n",
       "1                    missing              missing                    missing   \n",
       "2                    missing              missing                    missing   \n",
       "3                    missing              missing                    missing   \n",
       "4                    missing              missing                    missing   \n",
       "...                      ...                  ...                        ...   \n",
       "7271                      si              missing                    missing   \n",
       "7272                      si              missing                    missing   \n",
       "7273                      si              missing                    missing   \n",
       "7274                      si              missing                    missing   \n",
       "7275                      si              missing                    missing   \n",
       "\n",
       "final_col other_energy_household propane_gas_cooking  \\\n",
       "0                        missing                  no   \n",
       "1                        missing                  no   \n",
       "2                        missing                  no   \n",
       "3                        missing                  no   \n",
       "4                        missing                  no   \n",
       "...                          ...                 ...   \n",
       "7271                     missing             missing   \n",
       "7272                     missing             missing   \n",
       "7273                     missing             missing   \n",
       "7274                     missing             missing   \n",
       "7275                     missing             missing   \n",
       "\n",
       "final_col propane_gas_home_business propane_gas_household  \n",
       "0                                no                    si  \n",
       "1                                no                    si  \n",
       "2                                no                    si  \n",
       "3                                no                    si  \n",
       "4                                no                    si  \n",
       "...                             ...                   ...  \n",
       "7271                        missing               missing  \n",
       "7272                        missing               missing  \n",
       "7273                        missing               missing  \n",
       "7274                        missing               missing  \n",
       "7275                        missing               missing  \n",
       "\n",
       "[7276 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: wide to long\n",
    "long_df = pd.melt(\n",
    "    ecv02h01,\n",
    "    id_vars=['hhid', 'item'],\n",
    "    value_vars=list(use_map.keys()),\n",
    "    var_name='use_code',\n",
    "    value_name='value'\n",
    ")\n",
    "\n",
    "# Step 4: generate col names\n",
    "long_df['energy'] = long_df['item'].map(energy_translation)\n",
    "long_df['use'] = long_df['use_code'].map(use_map)\n",
    "long_df['final_col'] = long_df['energy'] + '_' + long_df['use']\n",
    "\n",
    "# Step 5: pivot to wide format\n",
    "ecv02h01_cleaned = long_df.pivot_table(\n",
    "    index='hhid',\n",
    "    columns='final_col',\n",
    "    values='value',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Step 6: hhid as string in case errors\n",
    "ecv02h01_cleaned['hhid'] = ecv02h01_cleaned['hhid'].astype('Int64').astype('string')\n",
    "\n",
    "ecv02h01_cleaned.to_csv('../cleaned_data/ECV02H01_cleaned.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print('\\nData Types: ')\n",
    "print(ecv02h01_cleaned.dtypes)\n",
    "\n",
    "ecv02h01_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9aba0e",
   "metadata": {},
   "source": [
    "## 6. Clean ```ECV09P05``` - Demographic Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa5f744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p05a03     11629\n",
      "p05b05      8357\n",
      "p07b01      8244\n",
      "p07b06b    28687\n",
      "p07b29     18000\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhid</th>\n",
       "      <th>caso</th>\n",
       "      <th>sexo</th>\n",
       "      <th>edad</th>\n",
       "      <th>p05a02</th>\n",
       "      <th>p05a03</th>\n",
       "      <th>p05b05</th>\n",
       "      <th>p07b01</th>\n",
       "      <th>p07b06b</th>\n",
       "      <th>p07b29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>femenino</td>\n",
       "      <td>42.0</td>\n",
       "      <td>jefe (a)</td>\n",
       "      <td>viudo (a)</td>\n",
       "      <td>otro maya</td>\n",
       "      <td>lee y escribe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>primaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>femenino</td>\n",
       "      <td>23.0</td>\n",
       "      <td>hijo (a)</td>\n",
       "      <td>soltero (a)</td>\n",
       "      <td>otro maya</td>\n",
       "      <td>lee y escribe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>basicos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>masculino</td>\n",
       "      <td>19.0</td>\n",
       "      <td>hijo (a)</td>\n",
       "      <td>soltero (a)</td>\n",
       "      <td>otro maya</td>\n",
       "      <td>lee y escribe</td>\n",
       "      <td>6.0</td>\n",
       "      <td>diversificado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>femenino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nieto (a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>masculino</td>\n",
       "      <td>60.0</td>\n",
       "      <td>jefe (a)</td>\n",
       "      <td>unido (a)</td>\n",
       "      <td>no indigena</td>\n",
       "      <td>lee y escribe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>preparatoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37766</th>\n",
       "      <td>7276</td>\n",
       "      <td>6</td>\n",
       "      <td>masculino</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hijo (a)</td>\n",
       "      <td>soltero (a)</td>\n",
       "      <td>no indigena</td>\n",
       "      <td>no lee ni escribe</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37767</th>\n",
       "      <td>7276</td>\n",
       "      <td>7</td>\n",
       "      <td>masculino</td>\n",
       "      <td>8.0</td>\n",
       "      <td>hijo (a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no indigena</td>\n",
       "      <td>no lee ni escribe</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37768</th>\n",
       "      <td>7276</td>\n",
       "      <td>8</td>\n",
       "      <td>masculino</td>\n",
       "      <td>5.0</td>\n",
       "      <td>hijo (a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37769</th>\n",
       "      <td>7276</td>\n",
       "      <td>9</td>\n",
       "      <td>masculino</td>\n",
       "      <td>3.0</td>\n",
       "      <td>hijo (a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37770</th>\n",
       "      <td>7276</td>\n",
       "      <td>10</td>\n",
       "      <td>femenino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hijo (a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37771 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hhid caso       sexo  edad     p05a02       p05a03       p05b05  \\\n",
       "0         1    1   femenino  42.0   jefe (a)    viudo (a)    otro maya   \n",
       "1         1    2   femenino  23.0   hijo (a)  soltero (a)    otro maya   \n",
       "2         1    3  masculino  19.0   hijo (a)  soltero (a)    otro maya   \n",
       "3         1    4   femenino   0.0  nieto (a)          NaN          NaN   \n",
       "4         2    1  masculino  60.0   jefe (a)    unido (a)  no indigena   \n",
       "...     ...  ...        ...   ...        ...          ...          ...   \n",
       "37766  7276    6  masculino  10.0   hijo (a)  soltero (a)  no indigena   \n",
       "37767  7276    7  masculino   8.0   hijo (a)          NaN  no indigena   \n",
       "37768  7276    8  masculino   5.0   hijo (a)          NaN          NaN   \n",
       "37769  7276    9  masculino   3.0   hijo (a)          NaN          NaN   \n",
       "37770  7276   10   femenino   0.0   hijo (a)          NaN          NaN   \n",
       "\n",
       "                  p07b01  p07b06b         p07b29  \n",
       "0          lee y escribe      NaN       primaria  \n",
       "1          lee y escribe      2.0        basicos  \n",
       "2          lee y escribe      6.0  diversificado  \n",
       "3                    NaN      NaN            NaN  \n",
       "4          lee y escribe      NaN   preparatoria  \n",
       "...                  ...      ...            ...  \n",
       "37766  no lee ni escribe      1.0            NaN  \n",
       "37767  no lee ni escribe      1.0            NaN  \n",
       "37768                NaN      NaN            NaN  \n",
       "37769                NaN      NaN            NaN  \n",
       "37770                NaN      NaN            NaN  \n",
       "\n",
       "[37771 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecv09p05 = pd.read_csv('../intermediate_data/ECV09P05.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv09p05.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "\n",
    "# formatting labels\n",
    "ecv09p05['hhid'] = ecv09p05['hhid'].astype('int64').astype(str)\n",
    "ecv09p05['caso'] = ecv09p05['caso'].astype('int64').astype(str)\n",
    "ecv09p05.columns = ecv09p05.columns.str.lower()\n",
    "\n",
    "ecv09p05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a107f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count numbers of individuals in each household\n",
    "ecv09p05['sexo'] = ecv09p05['sexo'].str.lower()\n",
    "\n",
    "# Create boolean columns for each aggregation\n",
    "ecv09p05['num_male'] = ecv09p05['sexo'] == 'masculino'\n",
    "ecv09p05['num_female'] = ecv09p05['sexo'] == 'femenino'\n",
    "ecv09p05['num_children'] = ecv09p05['edad'] <= 17\n",
    "ecv09p05['num_adults'] = ecv09p05['edad'] >= 18\n",
    "ecv09p05['num_elderly'] = ecv09p05['edad'] >= 60\n",
    "\n",
    "# Aggregations\n",
    "agg_dict = {\n",
    "    'num_male': 'sum',\n",
    "    'num_female': 'sum',\n",
    "    'num_children': 'sum',\n",
    "    'num_adults': 'sum',\n",
    "    'num_elderly': 'sum',\n",
    "}\n",
    "\n",
    "hh_counts = ecv09p05.groupby('hhid').agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8cb0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Extract the relevant information of the household head (based on p05a02 = 'jefe (a)')\n",
    "ecv09p05['p05a02'] = ecv09p05['p05a02'].str.lower()\n",
    "ecv09p05['p05a03'] = ecv09p05['p05a03'].str.lower()\n",
    "ecv09p05['p05b05'] = ecv09p05['p05b05'].str.lower()\n",
    "\n",
    "# Take out the row of the household head\n",
    "hh_head_rows = ecv09p05[ecv09p05['p05a02'] == 'jefe (a)'].copy()\n",
    "\n",
    "# Household head information\n",
    "hh_head_info = hh_head_rows[['hhid', 'sexo', 'edad', 'p05a03', 'p05b05', 'p07b01', 'p07b29']].copy()\n",
    "hh_head_info = hh_head_info.rename(columns={\n",
    "    'sexo': 'hh_head_gender',\n",
    "    'edad': 'hh_head_age',\n",
    "    'p05a03': 'hh_head_marital_status',\n",
    "    'p05b05': 'hh_head_ethnicity',\n",
    "    'p07b01': 'hh_head_literacy',\n",
    "    'p07b29': 'hh_head_education_level'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ae3e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\AppData\\Local\\Temp\\ipykernel_7772\\2649093771.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  max_edu = ecv09p05.groupby('hhid').apply(\n"
     ]
    }
   ],
   "source": [
    "# Step 4: The person with the highest educational attainment in each household (educational level)\n",
    "# Educational hierarchy ranking mapping\n",
    "edu_rank = {\n",
    "    'preparatoria': 1,\n",
    "    'primaria': 2,\n",
    "    'basicos': 3,\n",
    "    'diversificado': 4,\n",
    "    'universitario': 5,\n",
    "    'post-grado': 6\n",
    "}\n",
    "\n",
    "ecv09p05['p07b29'] = ecv09p05['p07b29'].str.lower()\n",
    "ecv09p05['edu_score'] = ecv09p05['p07b29'].map(edu_rank)\n",
    "\n",
    "max_edu = ecv09p05.groupby('hhid').apply(\n",
    "    lambda x: x.loc[x['edu_score'].idxmax(), 'p07b29'] if x['edu_score'].notna().any() else 'missing'\n",
    ").reset_index(name='max_education_level')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eee7b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\AppData\\Local\\Temp\\ipykernel_7772\\3415680403.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  female_max_edu = adult_female.groupby('hhid').apply(\n"
     ]
    }
   ],
   "source": [
    "# Step 5: The adult female with the highest educational attainment\n",
    "adult_female = ecv09p05[(ecv09p05['sexo'] == 'femenino') & (ecv09p05['edad'] >= 18)].copy()\n",
    "adult_female['edu_score'] = adult_female['p07b29'].map(edu_rank)\n",
    "\n",
    "female_max_edu = adult_female.groupby('hhid').apply(\n",
    "    lambda x: x.loc[x['edu_score'].idxmax(), 'p07b29'] if x['edu_score'].notna().any() else 'missing'\n",
    ").reset_index(name='female_max_education_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f4ef0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: The number of children currently enrolled (edad <= 17 and p07b06b not empty)\n",
    "school_age_children = ecv09p05[(ecv09p05['edad'] <= 17) & (ecv09p05['p07b06b'].notna())]\n",
    "num_enrolled_children = school_age_children.groupby('hhid').size().reset_index(name='num_children_enrolled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "755c4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init household dataframe\n",
    "from functools import reduce\n",
    "\n",
    "dfs = [\n",
    "    hh_counts,\n",
    "    hh_head_info,\n",
    "    max_edu,\n",
    "    female_max_edu,\n",
    "    num_enrolled_children\n",
    "]\n",
    "\n",
    "# Use reduce to merge all Dataframes (left join)\n",
    "from functools import reduce\n",
    "household_summary = reduce(lambda left, right: pd.merge(left, right, on='hhid', how='left'), dfs)\n",
    "\n",
    "# Completion of missing values\n",
    "household_summary['hh_head_education_level'] = household_summary['hh_head_education_level'].fillna('missing')\n",
    "household_summary['female_max_education_level'] = household_summary['female_max_education_level'].fillna('missing')\n",
    "\n",
    "count_vars = [\n",
    "    'num_male', 'num_female', 'num_children', 'num_adults',\n",
    "    'num_elderly', 'num_children_enrolled'\n",
    "]\n",
    "\n",
    "for col in count_vars:\n",
    "    if col in household_summary.columns:\n",
    "        household_summary[col] = household_summary[col].fillna(0).astype(int)\n",
    "\n",
    "# Sort hhid by integer\n",
    "household_summary['hhid_sort'] = household_summary['hhid'].astype(int)\n",
    "household_summary = household_summary.sort_values('hhid_sort').drop(columns='hhid_sort')\n",
    "\n",
    "household_summary['hhid'] = household_summary['hhid'].astype(str)\n",
    "household_summary['hh_head_age'] = household_summary['hh_head_age'].astype(int).astype(str)\n",
    "\n",
    "household_summary.to_csv('../cleaned_data/ECV09P05_cleaned.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50fee500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "   hhid  num_male  num_female  num_children  num_adults  num_elderly  \\\n",
      "0     1         1           3             1           3            0   \n",
      "1     2         2           1             0           3            2   \n",
      "2     3         5           1             2           4            0   \n",
      "3     4         0           1             0           1            1   \n",
      "4     5         2           1             1           2            0   \n",
      "\n",
      "  hh_head_gender  hh_head_age hh_head_marital_status hh_head_ethnicity  \\\n",
      "0       femenino           42              viudo (a)         otro maya   \n",
      "1      masculino           60              unido (a)       no indigena   \n",
      "2      masculino           51             casado (a)       no indigena   \n",
      "3       femenino           89              viudo (a)       no indigena   \n",
      "4      masculino           49             casado (a)       no indigena   \n",
      "\n",
      "  hh_head_literacy hh_head_education_level max_education_level  \\\n",
      "0    lee y escribe                primaria       diversificado   \n",
      "1    lee y escribe            preparatoria        preparatoria   \n",
      "2    lee y escribe            preparatoria       diversificado   \n",
      "3    lee y escribe            preparatoria        preparatoria   \n",
      "4    lee y escribe           universitario       universitario   \n",
      "\n",
      "  female_max_education_level  num_children_enrolled  \n",
      "0                    basicos                      0  \n",
      "1               preparatoria                      0  \n",
      "2                    missing                      2  \n",
      "3               preparatoria                      0  \n",
      "4              diversificado                      0  \n"
     ]
    }
   ],
   "source": [
    "ecv09p05_cleaned = pd.read_csv('../cleaned_data/ECV09P05_cleaned.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv09p05_cleaned.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv09p05_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350dda92",
   "metadata": {},
   "source": [
    "## 7. Clean ```ECV11P10``` - Household's living activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f23fb44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p10d01     15024\n",
      "p10d03     27023\n",
      "p10d04     27020\n",
      "p10d06     27023\n",
      "p10e05a    31482\n",
      "dtype: int64\n",
      "   hhid  caso p10d01 p10d03 p10d04 p10d06 p10e05a\n",
      "0   1.0   1.0    NaN    NaN    NaN    NaN     NaN\n",
      "1   1.0   2.0     no    NaN    NaN    NaN     NaN\n",
      "2   1.0   3.0     no    NaN    NaN    NaN     NaN\n",
      "3   2.0   1.0     no    NaN    NaN    NaN     NaN\n",
      "4   2.0   2.0    NaN    NaN    NaN    NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "ecv11p10 = pd.read_csv('../intermediate_data/ECV11P10.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv11p10.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv11p10.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0927d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type\n",
    "ecv11p10.columns = ecv11p10.columns.str.lower()\n",
    "ecv11p10['hhid'] = ecv11p10['hhid'].astype('int64').astype(str)\n",
    "ecv11p10['caso'] = ecv11p10['caso'].astype('int64').astype(str)\n",
    "# Only retain the household head information (caso == '1')\n",
    "hh_head_livelihood = ecv11p10[ecv11p10['caso'] == '1'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e9ef524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain the specified field\n",
    "selected_cols = ['hhid', 'p10d01', 'p10d03', 'p10d04', 'p10d06', 'p10e05a']\n",
    "hh_head_livelihood = hh_head_livelihood[selected_cols]\n",
    "\n",
    "# Handle missing values (fill 'missing' in all columns except hhid)\n",
    "for col in hh_head_livelihood.columns:\n",
    "    if col != 'hhid':\n",
    "        hh_head_livelihood[col] = hh_head_livelihood[col].fillna('missing')\n",
    "\n",
    "hh_head_livelihood.to_csv('../cleaned_data/ECV11P10_cleaned.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75d22270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "   hhid   p10d01   p10d03   p10d04   p10d06  p10e05a\n",
      "0     1  missing  missing  missing  missing  missing\n",
      "1     2       no  missing  missing  missing  missing\n",
      "2     3       no  missing  missing  missing  missing\n",
      "3     4  missing  missing  missing  missing  missing\n",
      "4     5       no  missing  missing  missing  missing\n"
     ]
    }
   ],
   "source": [
    "ecv11p10_clean = pd.read_csv('../cleaned_data/ECV11P10_cleaned.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv11p10_clean.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv11p10_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1be3af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hhids = pd.DataFrame({'hhid': [i for i in range(1, 7277)]})\n",
    "\n",
    "df_full = full_hhids.merge(ecv11p10_clean, on='hhid', how='left')\n",
    "\n",
    "# except for hhid，all missing value = 'missing'\n",
    "for col in df_full.columns:\n",
    "    if col != 'hhid':\n",
    "        df_full[col] = df_full[col].fillna('missing')\n",
    "\n",
    "df_full.to_csv('../cleaned_data/ECV11P10_cleaned.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934869f",
   "metadata": {},
   "source": [
    "## 8. Clean ```ECV17E14``` - Home Equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50978bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p10d01     15024\n",
      "p10d03     27023\n",
      "p10d04     27020\n",
      "p10d06     27023\n",
      "p10e05a    31482\n",
      "dtype: int64\n",
      "   hhid                  tipo                       item p14a01  p14a02\n",
      "0   1.0   articulos de cocina  estufa de gas / electrica     si     2.0\n",
      "1   1.0   articulos de cocina        horno de microondas     no     NaN\n",
      "2   1.0   articulos de cocina         horno convencional     no     NaN\n",
      "3   1.0   articulos de cocina              refrigeradora     si     1.0\n",
      "4   1.0   articulos de cocina         cafetera electrica     no     NaN\n"
     ]
    }
   ],
   "source": [
    "ecv17e14 = pd.read_csv('../intermediate_data//ECV17E14.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv11p10.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv17e14.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aafb0331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 ['estufa de gas / electrica' 'horno de microondas' 'horno convencional'\n",
      " 'refrigeradora' 'cafetera electrica' 'licuadora' 'exprimidor de jugos'\n",
      " 'molino de nixtamal y otros' 'computadora personal' 'impresora'\n",
      " 'camara fotografica' 'radio transistor' 'componente con cd'\n",
      " 'grabadora / radiograbadora' 'maquina de escribir' 'televisor'\n",
      " 'camara de video' 'video - camara / cassetera' 'otro de esparcimiento'\n",
      " 'beeper' 'telefono' 'plancha electrica' 'plancha de brazas' 'lavadora'\n",
      " 'secadora' 'ventilador' 'aspiradora' 'maquina de coser'\n",
      " 'otro articulo del hogar' 'automovil' 'pick up' 'camionetilla'\n",
      " 'moto o motoneta' 'bicicleta' 'carreta de bueyes' 'camion'\n",
      " 'bote o lancha' 'otro vehiculo']\n"
     ]
    }
   ],
   "source": [
    "# Check the number of non-repetitive values in the \"item\" column\n",
    "num_unique, unique_values = ecv17e14[\"item\"].nunique(), ecv17e14[\"item\"].unique()\n",
    "print(num_unique, unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2872211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# standardized column names are in lowercase\n",
    "ecv17e14.columns = ecv17e14.columns.str.lower()\n",
    "ecv17e14['hhid'] = ecv17e14['hhid'].astype('Int64')\n",
    "\n",
    "# Handle the outlier p14a01 and generate the \"Quantity of Items\" column\n",
    "ecv17e14['p14a01'] = ecv17e14['p14a01'].astype(str).str.lower()\n",
    "\n",
    "def clean_quantity(row):\n",
    "    if row['p14a01'] == 'no':\n",
    "        return 0\n",
    "    elif row['p14a01'] == 'si':\n",
    "        return row['p14a02']\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "ecv17e14['p14a02'] = ecv17e14.apply(clean_quantity, axis=1)\n",
    "ecv17e14['p14a02'] = ecv17e14['p14a02'].fillna(0).astype(int)\n",
    "\n",
    "# Use OrderedDict to retain the translation order of items\n",
    "item_translation = OrderedDict([\n",
    "    ('estufa de gas / electrica', 'gas_stove'),\n",
    "    ('horno de microondas', 'microwave'),\n",
    "    ('horno convencional', 'oven'),\n",
    "    ('refrigeradora', 'refrigerator'),\n",
    "    ('cafetera electrica', 'coffee_maker'),\n",
    "    ('licuadora', 'blender'),\n",
    "    ('exprimidor de jugos', 'juicer'),\n",
    "    ('molino de nixtamal y otros', 'nixtamal_mill'),\n",
    "    ('computadora personal', 'computer'),\n",
    "    ('impresora', 'printer'),\n",
    "    ('camara fotografica', 'camera'),\n",
    "    ('radio transistor', 'radio'),\n",
    "    ('componente con cd', 'cd_player'),\n",
    "    ('grabadora / radiograbadora', 'tape_recorder'),\n",
    "    ('maquina de escribir', 'typewriter'),\n",
    "    ('televisor', 'tv'),\n",
    "    ('camara de video', 'video_camera'),\n",
    "    ('video - camara / cassetera', 'cassette_camera'),\n",
    "    ('otro de esparcimiento', 'other_entertainment'),\n",
    "    ('beeper', 'beeper'),\n",
    "    ('telefono', 'phone'),\n",
    "    ('plancha electrica', 'electric_iron'),\n",
    "    ('plancha de brazas', 'charcoal_iron'),\n",
    "    ('lavadora', 'washer'),\n",
    "    ('secadora', 'dryer'),\n",
    "    ('ventilador', 'fan'),\n",
    "    ('aspiradora', 'vacuum'),\n",
    "    ('maquina de coser', 'sewing_machine'),\n",
    "    ('otro articulo del hogar', 'other_household_item'),\n",
    "    ('automovil', 'car'),\n",
    "    ('pick up', 'pickup'),\n",
    "    ('camionetilla', 'small_truck'),\n",
    "    ('moto o motoneta', 'motorcycle'),\n",
    "    ('bicicleta', 'bicycle'),\n",
    "    ('carreta de bueyes', 'ox_cart'),\n",
    "    ('camion', 'truck'),\n",
    "    ('bote o lancha', 'boat'),\n",
    "    ('otro vehiculo', 'other_vehicle')\n",
    "])\n",
    "\n",
    "# Add the translation column and the variable list\n",
    "ecv17e14['item_en'] = ecv17e14['item'].map(item_translation)\n",
    "ecv17e14['var_name'] = 'num_' + ecv17e14['item_en']\n",
    "\n",
    "# pivot to wide format\n",
    "ecv17e14_cleaned = ecv17e14.pivot_table(\n",
    "    index='hhid',\n",
    "    columns='var_name',\n",
    "    values='p14a02',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "ecv17e14_cleaned['hhid_sort'] = ecv17e14_cleaned['hhid'].astype(int)\n",
    "ecv17e14_cleaned = ecv17e14_cleaned.sort_values('hhid_sort').drop(columns='hhid_sort')\n",
    "\n",
    "# Arrange the variable columns in the original order\n",
    "ordered_cols = ['hhid'] + ['num_' + item_translation[item] for item in item_translation]\n",
    "ecv17e14_cleaned = ecv17e14_cleaned[ordered_cols]\n",
    "\n",
    "ecv17e14_cleaned.to_csv('../cleaned_data/ECV17E14_cleaned.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12fb67e",
   "metadata": {},
   "source": [
    "## 9. Clean ```ECV18N15``` - Enterprise Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9542fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p15b02    4624\n",
      "dtype: int64\n",
      "   hhid p15b01  p15b02\n",
      "0   1.0     no     NaN\n",
      "1   2.0     si     1.0\n",
      "2   3.0     no     NaN\n",
      "3   4.0     no     NaN\n",
      "4   5.0     si     1.0\n"
     ]
    }
   ],
   "source": [
    "ecv18n15 = pd.read_csv('../intermediate_data//ECV18N15.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv18n15.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv18n15.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4de01339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        hhid p15b01  p15b02\n",
      "1446  1447.0     no     1.0\n",
      "2239  2240.0     no     1.0\n"
     ]
    }
   ],
   "source": [
    "ecv18n15[\"p15b01\"] = ecv18n15[\"p15b01\"].str.lower()\n",
    "inconsistent = ecv18n15[(ecv18n15[\"p15b01\"] == \"no\") & (ecv18n15[\"p15b02\"] > 0)]\n",
    "print(inconsistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2399c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecv18n15['hhid'] = ecv18n15['hhid'].astype('Int64').astype(str)\n",
    "ecv18n15['p15b02'] = ecv18n15['p15b02'].fillna(0).astype(int).astype(str)\n",
    "ecv18n15.to_csv('../cleaned_data/ECV18N15_cleaned.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b556d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "   hhid p15b01  p15b02\n",
      "0     1     no       0\n",
      "1     2     si       1\n",
      "2     3     no       0\n",
      "3     4     no       0\n",
      "4     5     si       1\n"
     ]
    }
   ],
   "source": [
    "ecv18n15_clean = pd.read_csv('../cleaned_data/ECV18N15_cleaned.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv18n15_clean.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv18n15_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4c538",
   "metadata": {},
   "source": [
    "## 10. Check ```ECV19N15``` - Business details - whether remain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84b8e0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "   hhid                    p15b04\n",
      "0   2.0   industria manufacturera\n",
      "1   5.0                  comercio\n",
      "2   8.0                  comercio\n",
      "3   9.0   industria manufacturera\n",
      "4   9.0   industria manufacturera\n"
     ]
    }
   ],
   "source": [
    "ecv19n15 = pd.read_csv('../intermediate_data//ECV19N15.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv19n15.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv19n15.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aba66ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 [' industria manufacturera' ' comercio' ' servicios financieros'\n",
      " ' servicios de salud, sociales y personales' ' enseÑanza' ' construccion'\n",
      " ' agricultura, ganaderia, caza y pesca'\n",
      " ' transporte, almacenamiento y comunicaciones'\n",
      " ' administracion publica y defensa' ' actividad no especificada'\n",
      " ' electricidad, gas y agua' ' explotacion de minas y canteras']\n"
     ]
    }
   ],
   "source": [
    "# Check the number of non-repetitive values in the \"item\" column\n",
    "num_unique, unique_values = ecv19n15[\"p15b04\"].nunique(), ecv19n15[\"p15b04\"].unique()\n",
    "print(num_unique, unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6070db0",
   "metadata": {},
   "source": [
    "Veriry first: For each hhid, is the p15b02 value (number of enterprises) in ecv18n15_cleaned equal to the number of rows (corresponding number of enterprise industries) of the hhid in ecv19n15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95298466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ecv18n15 = pd.read_csv('../cleaned_data/ECV18N15_cleaned.csv', encoding='utf-8-sig')\n",
    "ecv19n15 = pd.read_csv('../intermediate_data/ECV19N15.csv', encoding='utf-8-sig')\n",
    "\n",
    "ecv18n15['hhid'] = ecv18n15['hhid'].astype(int)\n",
    "ecv18n15['p15b02'] = ecv18n15['p15b02'].astype(int)\n",
    "ecv19n15.columns = ecv19n15.columns.str.lower()\n",
    "ecv19n15['hhid'] = ecv19n15['hhid'].astype(int)\n",
    "\n",
    "# Only the families with business in ecv18n15 (p15b02 > 0) will be retained.\n",
    "business_hh = ecv18n15[ecv18n15['p15b02'] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7a2f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ There are  10 inconsistencies among families\n",
      "      hhid  p15b02  num_industries_reported\n",
      "134    336       2                        1\n",
      "140    346       2                        1\n",
      "141    347       2                        1\n",
      "549   1306       1                        0\n",
      "566   1349       2                        1\n",
      "1085  2763       2                        0\n",
      "1086  2764       2                        0\n",
      "1244  3120       3                        2\n",
      "1726  4599       2                        1\n",
      "2121  5641       1                        0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of industry items in ecv19n15\n",
    "industry_counts = ecv19n15.groupby('hhid').size().reset_index(name='num_industries_reported')\n",
    "# merge\n",
    "validation_df = business_hh.merge(industry_counts, on='hhid', how='left')\n",
    "validation_df['num_industries_reported'] = validation_df['num_industries_reported'].fillna(0).astype(int)\n",
    "\n",
    "# Verify consistency\n",
    "validation_df['match'] = validation_df['p15b02'] == validation_df['num_industries_reported']\n",
    "mismatched = validation_df[validation_df['match'] == False]\n",
    "\n",
    "if mismatched.empty:\n",
    "    print(\"done\")\n",
    "else:\n",
    "    print(f\"❗ There are  {len(mismatched)} inconsistencies among families\") \n",
    "    print(mismatched[['hhid', 'p15b02', 'num_industries_reported']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edaa2f5",
   "metadata": {},
   "source": [
    "## 11. Clean ```ECV21A16``` - Amount of land owned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9d4bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "    hhid                         tipo                            tcuerda  \\\n",
      "0   28.0                     agricola  cuerda/tarea de 25 varas por lado   \n",
      "1   31.0                     agricola  cuerda/tarea de 25 varas por lado   \n",
      "2  297.0                     agricola  cuerda/tarea de 25 varas por lado   \n",
      "3  363.0  mixta (agricola y pecuaria)  cuerda/tarea de 25 varas por lado   \n",
      "4  378.0                     agricola  cuerda/tarea de 25 varas por lado   \n",
      "\n",
      "   p16a07a  p16a07b  \n",
      "0      1.0  manzana  \n",
      "1     10.0   cuerda  \n",
      "2     10.0  manzana  \n",
      "3      2.0   cuerda  \n",
      "4      5.0  manzana  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ecv21a16 = pd.read_csv('../intermediate_data/ECV21A16.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv21a16.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv21a16.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47f9ec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: hhid\n",
      "Unique values (2523): [ 28.  31. 297. 363. 378. 471. 472. 477. 478. 508.]\n",
      "\n",
      "Column: tipo\n",
      "Unique values (2): ['agricola' 'mixta (agricola y pecuaria)']\n",
      "\n",
      "Column: tcuerda\n",
      "Unique values (8): ['cuerda/tarea de 25 varas por lado' 'cuerda/tarea de 20 varas por lado'\n",
      " 'cuerda/tarea de 30 varas por lado' 'cuerda/tarea de 40 varas por lado'\n",
      " 'cuerda/tarea de 32 varas por lado' 'cuerda/tarea de 24 varas por lado'\n",
      " 'cuerda/tarea de 28 varas por lado' 'cuerda/tarea de 50 varas por lado']\n",
      "\n",
      "Column: p16a07a\n",
      "Unique values (109): [ 1.  10.   2.   5.   3.  12.   1.5  7.   4.5  4. ]\n",
      "\n",
      "Column: p16a07b\n",
      "Unique values (5): ['manzana' 'cuerda' 'hectarea' 'caballeria' 'tarea']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in ecv21a16.columns:\n",
    "    unique_vals = ecv21a16[col].dropna().unique()\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Unique values ({len(unique_vals)}): {unique_vals[:10]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf08babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ecv21a16.columns = ecv21a16.columns.str.lower()\n",
    "ecv21a16['hhid'] = ecv21a16['hhid'].astype(int)\n",
    "\n",
    "# Extract the vara value (\"xx varas\" in tcuerda)\n",
    "def extract_vara(val):\n",
    "    match = re.search(r'(\\d+)', val)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "ecv21a16['vara_length'] = ecv21a16['tcuerda'].apply(extract_vara)\n",
    "\n",
    "# Define the unit conversion function (return square meters)\n",
    "def convert_to_sqm(row):\n",
    "    value = row['p16a07a']\n",
    "    unit = str(row['p16a07b']).strip().lower()\n",
    "    vara = row['vara_length']\n",
    "    \n",
    "    if pd.isna(value) or value == '':\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        value = float(value)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    if unit == 'manzana':\n",
    "        return value * 6987\n",
    "    elif unit == 'hectarea':\n",
    "        return value * 10000\n",
    "    elif unit == 'caballeria':\n",
    "        return value * 78.58 * 10000\n",
    "    elif unit in ['cuerda', 'tarea']:\n",
    "        if pd.isna(vara):\n",
    "            return 0\n",
    "        else:\n",
    "            vara_length_m = vara * 0.8421\n",
    "            return value * (vara_length_m ** 2)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply conversion functions\n",
    "ecv21a16['land_area_sqm'] = ecv21a16.apply(convert_to_sqm, axis=1)\n",
    "\n",
    "# Apply conversion functions\n",
    "land_area_by_hh = ecv21a16.groupby('hhid')['land_area_sqm'].sum().reset_index()\n",
    "\n",
    "full_hhids = pd.DataFrame({'hhid': [i for i in range(1, 7277)]})\n",
    "\n",
    "# Summarize the existing area according to hhid\n",
    "land_area_by_hh = ecv21a16.groupby('hhid')['land_area_sqm'].sum().reset_index()\n",
    "land_area_by_hh = full_hhids.merge(land_area_by_hh, on='hhid', how='left')\n",
    "land_area_by_hh['land_area_sqm'] = land_area_by_hh['land_area_sqm'].fillna(0)\n",
    "\n",
    "land_area_by_hh.to_csv('../cleaned_data/ECV21A16_cleaned.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ef35e",
   "metadata": {},
   "source": [
    "## 12. Clean ```ECV28A16``` - Agricultural equipment and facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7901400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p16g02    92052\n",
      "dtype: int64\n",
      "   hhid      tipo                        item p16g01  p16g02\n",
      "0  28.0  agricola  implementos de tiro animal     no     NaN\n",
      "1  28.0  agricola                     tractor     no     NaN\n",
      "2  28.0  agricola    implementos para tractor     no     NaN\n",
      "3  28.0  agricola                 cosechadora     no     NaN\n",
      "4  28.0  agricola    sembradora o cultivadora     no     NaN\n"
     ]
    }
   ],
   "source": [
    "ecv28a16 = pd.read_csv('../intermediate_data/ECV28A16.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv28a16.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv28a16.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b3b03152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 ['implementos de tiro animal' 'tractor' 'implementos para tractor'\n",
      " 'cosechadora' 'sembradora o cultivadora' 'bomba de agua'\n",
      " 'camion, camioneta, jeep' 'animales de trabajo' 'bomba fumigadora'\n",
      " 'planta electrica' 'equipo de riego' 'pequeÑas herramientas' 'ordeÑadora'\n",
      " 'picadora de zacate' 'desgranadora' 'carretas' 'otro equipo'\n",
      " 'cobertizo/galera' 'molinos' 'tanques' 'pozos' 'baÑaderos' 'silos'\n",
      " 'secaderos' 'abrevaderos' 'otra instalacion']\n",
      "['no' 'si']\n",
      "[ nan   1.  24.   5.   2.   6.   4.   3.  10.   8.  11.   7.  12.   9.\n",
      "  17.  14.  15.  30.  18.  20.  33.  13.  22.  16.   0. 110. 100.  80.\n",
      "  19.  25.  21.  44.  60. 200.  63. 101.  32.  23. 126.  40.  28.  70.\n",
      "  65.  29.  59.  48.  54.  58.  51. 132. 145. 112.]\n"
     ]
    }
   ],
   "source": [
    "print(ecv28a16['item'].nunique(), ecv28a16['item'].unique())\n",
    "print(ecv28a16['p16g01'].unique())\n",
    "print(ecv28a16['p16g02'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3cdd3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Filter out the records where p16g01 is \"no\"\n",
    "p16g01 = ecv28a16[ecv28a16[\"p16g01\"].str.lower() == \"no\"]\n",
    "# Check whether the p16g02 of all these records is 0\n",
    "all_na = p16g01[\"p16g02\"].isna().all()\n",
    "print(all_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73dfda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "ecv28a16 = pd.read_csv('../intermediate_data/ECV28A16.csv', encoding='utf-8-sig')\n",
    "ecv28a16.columns = ecv28a16.columns.str.lower()\n",
    "\n",
    "ecv28a16['hhid'] = ecv28a16['hhid'].astype('Int64').astype(str)\n",
    "\n",
    "# When cleaning p16g01 = 'no', p16g02 should be set to 0\n",
    "ecv28a16['p16g01'] = ecv28a16['p16g01'].str.lower().str.strip()\n",
    "ecv28a16['p16g02'] = ecv28a16.apply(\n",
    "    lambda row: 0 if row['p16g01'] == 'no' else row['p16g02'],\n",
    "    axis=1\n",
    ")\n",
    "ecv28a16['p16g02'] = ecv28a16['p16g02'].fillna(0).astype(int)\n",
    "\n",
    "# Use OrderedDict to maintain the translation order of the facility\n",
    "item_translation = OrderedDict([\n",
    "    ('implementos de tiro animal', 'animal_drawn_equipment'),\n",
    "    ('tractor', 'tractor'),\n",
    "    ('implementos para tractor', 'tractor_equipment'),\n",
    "    ('cosechadora', 'harvester'),\n",
    "    ('sembradora o cultivadora', 'seeder_cultivator'),\n",
    "    ('bomba de agua', 'water_pump'),\n",
    "    ('camion, camioneta, jeep', 'vehicle'),\n",
    "    ('animales de trabajo', 'work_animals'),\n",
    "    ('bomba fumigadora', 'fumigation_pump'),\n",
    "    ('planta electrica', 'generator'),\n",
    "    ('equipo de riego', 'irrigation_equipment'),\n",
    "    ('pequeÑas herramientas', 'small_tools'),\n",
    "    ('ordeÑadora', 'milking_machine'),\n",
    "    ('picadora de zacate', 'forage_chopper'),\n",
    "    ('desgranadora', 'sheller'),\n",
    "    ('carretas', 'carts'),\n",
    "    ('otro equipo', 'other_equipment'),\n",
    "    ('cobertizo/galera', 'shed'),\n",
    "    ('molinos', 'mills'),\n",
    "    ('tanques', 'tanks'),\n",
    "    ('pozos', 'wells'),\n",
    "    ('baÑaderos', 'baths'),\n",
    "    ('silos', 'silos'),\n",
    "    ('secaderos', 'dryers'),\n",
    "    ('abrevaderos', 'watering_troughs'),\n",
    "    ('otra instalacion', 'other_facility')\n",
    "])\n",
    "\n",
    "# Add English variable names\n",
    "ecv28a16['item_en'] = ecv28a16['item'].map(item_translation)\n",
    "ecv28a16['var_name'] = 'num_' + ecv28a16['item_en']\n",
    "\n",
    "# pivot and aggregate into sum (for handling duplicate rows)\n",
    "wide_df = ecv28a16.pivot_table(\n",
    "    index='hhid',\n",
    "    columns='var_name',\n",
    "    values='p16g02',\n",
    "    aggfunc='sum'\n",
    ").reset_index()\n",
    "\n",
    "# Construct the complete hhid (1-7276), and the completion is 0\n",
    "full_hhids = pd.DataFrame({'hhid': [str(i) for i in range(1, 7277)]})\n",
    "wide_df = full_hhids.merge(wide_df, on='hhid', how='left')\n",
    "wide_df = wide_df.fillna(0).copy()\n",
    "\n",
    "# set original orger\n",
    "ordered_cols = ['hhid'] + ['num_' + item_translation[item] for item in item_translation]\n",
    "wide_df = wide_df[ordered_cols]\n",
    "\n",
    "wide_df['hhid_sort'] = wide_df['hhid'].astype(int)\n",
    "wide_df = wide_df.sort_values('hhid_sort').drop(columns='hhid_sort')\n",
    "wide_df['hhid'] = wide_df['hhid'].astype(str)\n",
    "\n",
    "wide_df.to_csv('../cleaned_data/ECV28A16_cleaned.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a0a0e3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_harvester\n",
       "0.0    7276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_df['num_harvester'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43444b7",
   "metadata": {},
   "source": [
    "## 13. Clean ```ECV31A16``` - Livestock Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10accf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "   hhid      tipo                    item p16j02  p16j03\n",
      "0  38.0  pecuaria  vacas, toros, terneros     no     0.0\n",
      "1  38.0  pecuaria                  cabras     no     0.0\n",
      "2  38.0  pecuaria                  ovejas     no     0.0\n",
      "3  38.0  pecuaria                  cerdos     no     0.0\n",
      "4  38.0  pecuaria                 conejos     no     0.0\n"
     ]
    }
   ],
   "source": [
    "ecv31a16 = pd.read_csv('../intermediate_data/ECV31A16.csv', encoding='utf-8-sig')\n",
    "missing_report = ecv31a16.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecv31a16.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27847d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ['vacas, toros, terneros' 'cabras' 'ovejas' 'cerdos' 'conejos'\n",
      " 'gallinas y pollos' 'pavos o chompipes' 'patos' 'caballos, burros, mulas'\n",
      " 'colmenas' 'otros animales']\n",
      "['no' 'si']\n",
      "[0.000e+00 1.100e+01 1.000e+00 2.000e+00 7.000e+00 1.000e+01 4.000e+00\n",
      " 8.000e+00 1.400e+01 1.600e+01 3.000e+00 1.200e+01 6.000e+00 4.500e+01\n",
      " 9.250e+02 5.000e+00 2.000e+01 1.300e+01 1.500e+01 2.500e+01 3.600e+01\n",
      " 3.500e+01 2.300e+01 1.700e+01 9.000e+00 5.000e+02 3.700e+01 7.500e+01\n",
      " 1.800e+01 2.600e+01 4.000e+01 3.000e+01 6.500e+01 2.400e+01 6.000e+01\n",
      " 2.200e+01 2.800e+01 2.700e+01 8.000e+01 4.800e+01 1.000e+03 1.800e+02\n",
      " 5.000e+01 1.000e+02 3.000e+03 2.100e+01 3.500e+02 1.900e+01 3.400e+01\n",
      " 3.800e+01 3.100e+01 2.900e+01 3.300e+01 7.000e+01 1.750e+02 6.700e+01\n",
      " 5.500e+01 3.200e+01 2.050e+02 1.600e+02 1.300e+02 1.200e+02 2.300e+04\n",
      " 2.000e+02 6.100e+01 2.500e+02 4.000e+02 4.400e+01 4.300e+01 1.200e+03\n",
      " 5.200e+01 1.500e+02 6.000e+02 4.000e+03 1.500e+03 8.000e+02 4.600e+01\n",
      " 4.100e+01 1.224e+04 9.000e+01 5.900e+01 8.300e+01 8.500e+01 5.300e+01\n",
      " 6.400e+01 2.250e+02 4.700e+01 1.215e+04 7.200e+01 1.020e+02 4.200e+01\n",
      " 8.900e+01]\n"
     ]
    }
   ],
   "source": [
    "print(ecv31a16['item'].nunique(), ecv31a16['item'].unique())\n",
    "print(ecv31a16['p16j02'].unique())\n",
    "print(ecv31a16['p16j03'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70568050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "ecv31a16.columns = ecv31a16.columns.str.lower()\n",
    "\n",
    "ecv31a16['hhid'] = ecv31a16['hhid'].astype(pd.Int64Dtype()).astype(str)\n",
    "\n",
    "# Use OrderedDict to maintain the translation order of animals\n",
    "animal_translation = OrderedDict([\n",
    "    ('vacas, toros, terneros', 'cattle'),\n",
    "    ('cabras', 'goats'),\n",
    "    ('ovejas', 'sheep'),\n",
    "    ('cerdos', 'pigs'),\n",
    "    ('conejos', 'rabbits'),\n",
    "    ('gallinas y pollos', 'chickens'),\n",
    "    ('pavos o chompipes', 'turkeys'),\n",
    "    ('patos', 'ducks'),\n",
    "    ('caballos, burros, mulas', 'horses_donkeys_mules'),\n",
    "    ('colmenas', 'beehives'),\n",
    "    ('otros animales', 'other_animals')\n",
    "])\n",
    "\n",
    "# 名Add English variable names\n",
    "ecv31a16['item_en'] = ecv31a16['item'].map(animal_translation)\n",
    "ecv31a16['var_name'] = 'num_' + ecv31a16['item_en']\n",
    "\n",
    "# pivot to wide format\n",
    "wide_df = ecv31a16.pivot_table(\n",
    "    index='hhid',\n",
    "    columns='var_name',\n",
    "    values='p16j03',\n",
    "    aggfunc='sum'\n",
    ").reset_index()\n",
    "\n",
    "# The complete hhid (1-7276) was constructed, and the completion was 0\n",
    "full_hhids = pd.DataFrame({'hhid': [str(i) for i in range(1, 7277)]})\n",
    "wide_df = full_hhids.merge(wide_df, on='hhid', how='left')\n",
    "wide_df = wide_df.fillna(0).copy()\n",
    "\n",
    "# clarify the column sequence (hhid 11 columns of animals)\n",
    "ordered_cols = ['hhid'] + ['num_' + animal_translation[item] for item in animal_translation]\n",
    "wide_df = wide_df[ordered_cols]\n",
    "\n",
    "wide_df['hhid_sort'] = wide_df['hhid'].astype(int)\n",
    "wide_df = wide_df.sort_values('hhid_sort').drop(columns='hhid_sort')\n",
    "wide_df['hhid'] = wide_df['hhid'].astype(str)\n",
    "\n",
    "wide_df.to_csv('../cleaned_data/ECV31A16_cleaned.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a4a44",
   "metadata": {},
   "source": [
    "## 14. Clean ```ECOM02``` - road availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f98116b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "   depto  mupio  sector  c02act  c02a01\n",
      "0      1      5      50       1       1\n",
      "1      1      5      50       2       2\n",
      "2      1      5      50       3       2\n",
      "3      1      5      50       4       2\n",
      "4      1      5      50       5       2\n"
     ]
    }
   ],
   "source": [
    "ecom02 = pd.read_csv('../intermediate_data/ECOM02.csv', encoding='utf-8-sig')\n",
    "missing_report = ecom02.isnull().sum()\n",
    "print(missing_report[missing_report>0])\n",
    "print(ecom02.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dea3a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ['guatemala', 'el progreso', 'sacatepequez', 'chimaltenango', 'escuintla', ..., 'izabal', 'zacapa', 'chiquimula', 'jalapa', 'jutiapa']\n",
      "Length: 22\n",
      "Categories (22, object): ['alta verapaz', 'baja verapaz', 'chimaltenango', 'chiquimula', ..., 'solola', 'suchitepequez', 'totonicapan', 'zacapa']\n",
      "8 [1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "print(consumo5['depto'].nunique(), consumo5['depto'].unique())\n",
    "print(ecom02['c02act'].nunique(), ecom02['c02act'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a90dce7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depto     int64\n",
       "mupio     int64\n",
       "sector    int64\n",
       "c02act    int64\n",
       "c02a01    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecom02.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aac232c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create provincial number - name mapping\n",
    "province_map = {\n",
    "    1: 'guatemala', 2: 'el progreso', 3: 'sacatepequez', 4: 'chimaltenango',\n",
    "    5: 'escuintla', 6: 'santa rosa', 7: 'solola', 8: 'totonicapan',\n",
    "    9: 'quetzaltenango', 10: 'suchitepequez', 11: 'retalhuleu', 12: 'san marcos',\n",
    "    13: 'huehuetenango', 14: 'quiche', 15: 'baja verapaz', 16: 'alta verapaz',\n",
    "    17: 'peten', 18: 'izabal', 19: 'zacapa', 20: 'chiquimula',\n",
    "    21: 'jalapa', 22: 'jutiapa'\n",
    "}\n",
    "ecom02['depto_name'] = ecom02['depto'].map(province_map)\n",
    "\n",
    "# OrderedDict ensures order\n",
    "transport_translation = OrderedDict([\n",
    "    (0, 'paved_or_gravel_road'),\n",
    "    (1, 'dirt_road'),\n",
    "    (2, 'footpath_no_gravel'),\n",
    "    (3, 'footpath'),\n",
    "    (4, 'sea_lake_river'),\n",
    "    (5, 'train'),\n",
    "    (6, 'airplane'),\n",
    "    (7, 'other')\n",
    "])\n",
    "ecom02['transport_index'] = ecom02.groupby(['depto_name', 'mupio', 'sector']).cumcount()\n",
    "ecom02['transport_en'] = ecom02['transport_index'].map(transport_translation)\n",
    "\n",
    "# ）The presence or absence of standardized transportation facilities (si/no)\n",
    "ecom02['has_transport'] = ecom02['c02a01'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# pivot to wide format\n",
    "ecom02_wide = ecom02.pivot_table(\n",
    "    index=['depto_name', 'mupio', 'sector'],\n",
    "    columns='transport_en',\n",
    "    values='has_transport',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# rename to has_<type>\n",
    "ecom02_wide.columns = ['depto', 'mupio', 'sector'] + [f'has_{col}' for col in ecom02_wide.columns[3:]]\n",
    "\n",
    "# prepare consumo5\n",
    "consumo5['hhid'] = consumo5['hhid'].astype(pd.Int64Dtype()).astype(str)\n",
    "consumo5['depto'] = consumo5['depto'].str.strip().str.lower()\n",
    "consumo5['mupio'] = consumo5['mupio'].astype(int)\n",
    "consumo5['sector'] = consumo5['sector'].astype(int)\n",
    "\n",
    "# merge with transport data\n",
    "merged = consumo5.merge(\n",
    "    ecom02_wide,\n",
    "    on=['depto', 'mupio', 'sector'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# missing\n",
    "transport_cols = [col for col in merged.columns if col.startswith('has_')]\n",
    "merged[transport_cols] = merged[transport_cols].fillna('missing')\n",
    "\n",
    "# ensure order\n",
    "transport_cols_ordered = [f'has_{v}' for v in transport_translation.values()]\n",
    "final_cols = ['hhid'] + transport_cols_ordered\n",
    "merged = merged[final_cols]\n",
    "\n",
    "merged.to_csv('../cleaned_data/ECOM02_cleaned.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3ed1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# province_map（name → code）\n",
    "province_code_map = {v: k for k, v in province_map.items()}\n",
    "\n",
    "# SExtract community identification information\n",
    "community_info = consumo5[['hhid', 'depto', 'mupio', 'sector']].copy()\n",
    "community_info['depto_code'] = community_info['depto'].map(province_code_map)\n",
    "community_info['depto_name'] = community_info['depto']\n",
    "\n",
    "# reorder\n",
    "community_info = community_info[['hhid', 'depto_code', 'depto_name', 'mupio', 'sector']]\n",
    "\n",
    "community_info.to_csv('../cleaned_data/geo_info_per_household.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56ef63",
   "metadata": {},
   "source": [
    "## 15. Clean ```ECOM03``` - infrastructure availablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28cb10d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing report:\n",
      "c02b01      351\n",
      "c02b02a    1597\n",
      "c02b02b    1535\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depto</th>\n",
       "      <th>mupio</th>\n",
       "      <th>sector</th>\n",
       "      <th>c02b01</th>\n",
       "      <th>c02b02a</th>\n",
       "      <th>c02b02b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11949</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11950</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11951</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11952</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11953</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11954 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depto  mupio  sector  c02b01  c02b02a  c02b02b\n",
       "0          1      5      50     1.0      1.0      2.0\n",
       "1          1      5      50     1.0      1.0      2.0\n",
       "2          1      5      50     1.0      1.0      2.0\n",
       "3          1      5      50     1.0      1.0      2.0\n",
       "4          1      5      50     1.0      1.0      2.0\n",
       "...      ...    ...     ...     ...      ...      ...\n",
       "11949     22     13       4     2.0      4.0      2.0\n",
       "11950     22     13       4     2.0     70.0      2.0\n",
       "11951     22     13       4     2.0      2.0      2.0\n",
       "11952     22     13       4     1.0      NaN      NaN\n",
       "11953     22     13       4     NaN      4.0      2.0\n",
       "\n",
       "[11954 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecom03 = pd.read_csv('../intermediate_data/ECOM03.csv', encoding='utf-8-sig')\n",
    "\n",
    "missing_report = ecom03.isnull().sum()\n",
    "print(\"Missing report:\")\n",
    "print(missing_report[missing_report>0])\n",
    "\n",
    "ecom03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a0cd6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c02b02b\n",
       "2.0    7225\n",
       "9.0    1162\n",
       "1.0    1000\n",
       "3.0     967\n",
       "4.0      65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecom03['c02b02b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc1a3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "facility_dict = OrderedDict({\n",
    "    1: \"preschool\",\n",
    "    2: \"primary_school\",\n",
    "    3: \"secondary_school\",\n",
    "    4: \"health_center\",\n",
    "    5: \"public_hospital\",\n",
    "    6: \"private_hospital\",\n",
    "    7: \"private_clinic\",\n",
    "    8: \"natural_healer\",\n",
    "    9: \"traditional_midwife\",\n",
    "    10: \"pharmacy\",\n",
    "    11: \"public_phone\",\n",
    "    12: \"mail_service\",\n",
    "    13: \"bus_stop\",\n",
    "    14: \"bank\",\n",
    "    15: \"cooperative\",\n",
    "    16: \"police_post\",\n",
    "    17: \"civil_registry\",\n",
    "    18: \"market\",\n",
    "    19: \"church\",\n",
    "    20: \"community_room\",\n",
    "    21: \"recreation_parks\",\n",
    "    22: \"firehouse\",\n",
    "    23: \"firewood_collection\",\n",
    "    24: \"water_collection\",\n",
    "    25: \"work_site\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cd75899",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_map = {\n",
    "    1: 1,\n",
    "    2: 1000,\n",
    "    3: 100,\n",
    "    4: 5572,\n",
    "    9: None,\n",
    "    None: None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7f4f1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhid</th>\n",
       "      <th>depto_code</th>\n",
       "      <th>depto_name</th>\n",
       "      <th>mupio</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>guatemala</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>guatemala</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>guatemala</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>guatemala</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>guatemala</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>7272</td>\n",
       "      <td>22</td>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>7273</td>\n",
       "      <td>22</td>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>7274</td>\n",
       "      <td>22</td>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>7275</td>\n",
       "      <td>22</td>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>7276</td>\n",
       "      <td>22</td>\n",
       "      <td>jutiapa</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7276 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hhid  depto_code depto_name  mupio  sector\n",
       "0        1           1  guatemala      3       3\n",
       "1        2           1  guatemala      3       3\n",
       "2        3           1  guatemala      3       3\n",
       "3        4           1  guatemala      3       3\n",
       "4        5           1  guatemala      3       3\n",
       "...    ...         ...        ...    ...     ...\n",
       "7271  7272          22    jutiapa     13       7\n",
       "7272  7273          22    jutiapa     13       7\n",
       "7273  7274          22    jutiapa     13       7\n",
       "7274  7275          22    jutiapa     13       7\n",
       "7275  7276          22    jutiapa     13       7\n",
       "\n",
       "[7276 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = pd.read_csv('../cleaned_data/geo_info_per_household.csv', encoding='utf-8-sig')\n",
    "\n",
    "geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d71d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecom03['c02b02b'] = pd.to_numeric(ecom03['c02b02b'], errors='coerce')  # ensures float dtype\n",
    "\n",
    "# Add the facility number (exactly 25 lines for each community)\n",
    "ecom03['infra_index'] = ecom03.groupby(['depto', 'mupio', 'sector']).cumcount() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7f73b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        2.0\n",
       "2        2.0\n",
       "3        2.0\n",
       "4        2.0\n",
       "        ... \n",
       "11949    2.0\n",
       "11950    2.0\n",
       "11951    2.0\n",
       "11952    NaN\n",
       "11953    2.0\n",
       "Name: c02b02b, Length: 11954, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecom03['c02b02b'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2e82e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depto</th>\n",
       "      <th>mupio</th>\n",
       "      <th>sector</th>\n",
       "      <th>c02b01</th>\n",
       "      <th>c02b02a</th>\n",
       "      <th>c02b02b</th>\n",
       "      <th>infra_index</th>\n",
       "      <th>unit_multiplier</th>\n",
       "      <th>distance_missingness</th>\n",
       "      <th>distance_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11949</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11950</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11951</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11952</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>27994.267603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11953</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11954 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       depto  mupio  sector  c02b01  c02b02a  c02b02b  infra_index  \\\n",
       "0          1      5      50     1.0      1.0      2.0            1   \n",
       "1          1      5      50     1.0      1.0      2.0            2   \n",
       "2          1      5      50     1.0      1.0      2.0            3   \n",
       "3          1      5      50     1.0      1.0      2.0            4   \n",
       "4          1      5      50     1.0      1.0      2.0            5   \n",
       "...      ...    ...     ...     ...      ...      ...          ...   \n",
       "11949     22     13       4     2.0      4.0      2.0           21   \n",
       "11950     22     13       4     2.0     70.0      2.0           22   \n",
       "11951     22     13       4     2.0      2.0      2.0           23   \n",
       "11952     22     13       4     1.0      NaN      NaN           24   \n",
       "11953     22     13       4     NaN      4.0      2.0           25   \n",
       "\n",
       "       unit_multiplier  distance_missingness    distance_m  \n",
       "0               1000.0                 False   1000.000000  \n",
       "1               1000.0                 False   1000.000000  \n",
       "2               1000.0                 False   1000.000000  \n",
       "3               1000.0                 False   1000.000000  \n",
       "4               1000.0                 False   1000.000000  \n",
       "...                ...                   ...           ...  \n",
       "11949           1000.0                 False   4000.000000  \n",
       "11950           1000.0                 False  70000.000000  \n",
       "11951           1000.0                 False   2000.000000  \n",
       "11952              NaN                  True  27994.267603  \n",
       "11953           1000.0                 False   4000.000000  \n",
       "\n",
       "[11954 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecom03['unit_multiplier'] = ecom03['c02b02b'].map(unit_map)\n",
    "\n",
    "ecom03['distance_missingness'] = ecom03['c02b02a'].isna() | ecom03['unit_multiplier'].isna()\n",
    "\n",
    "# Compute distance\n",
    "ecom03['distance_m'] = ecom03['c02b02a'] * ecom03['unit_multiplier']\n",
    "impute_mean_dist = ecom03['distance_m'].mean()\n",
    "ecom03['distance_m'] = ecom03['distance_m'].fillna(impute_mean_dist)  \n",
    "\n",
    "ecom03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff21e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain the designated facilities\n",
    "subset_keys = list(facility_dict.keys())\n",
    "keep_keys = subset_keys[:15] + [18]\n",
    "ecom03 = ecom03[ecom03['infra_index'].isin(keep_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "806510b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\AppData\\Local\\Temp\\ipykernel_7772\\360888750.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecom03['facility'] = ecom03['infra_index'].map(facility_dict)\n",
      "C:\\Users\\PB\\AppData\\Local\\Temp\\ipykernel_7772\\360888750.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecom03['distance_col'] = 'distance_' + ecom03['facility']\n"
     ]
    }
   ],
   "source": [
    "# add cols\n",
    "ecom03['facility'] = ecom03['infra_index'].map(facility_dict)\n",
    "ecom03['distance_col'] = 'distance_' + ecom03['facility']\n",
    "\n",
    "# Pivot to wide format\n",
    "distance_wide = ecom03.pivot_table(\n",
    "    index=['depto', 'mupio', 'sector'],\n",
    "    columns='distance_col',\n",
    "    values='distance_m',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0099b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize geo_info\n",
    "geo['depto'] = geo['depto_code'].astype(int)\n",
    "geo['mupio'] = geo['mupio'].astype(int)\n",
    "geo['sector'] = geo['sector'].astype(int)\n",
    "\n",
    "# Merge the distance of community infrastructure\n",
    "merged = geo.merge(distance_wide, on=['depto', 'mupio', 'sector'], how='left')\n",
    "\n",
    "# change missing to 99999999\n",
    "distance_cols = [f'distance_{facility_dict[k]}' for k in keep_keys]\n",
    "merged[distance_cols] = merged[distance_cols].fillna(99999999)\n",
    "\n",
    "ordered_cols = (\n",
    "    ['hhid'] +\n",
    "    distance_cols\n",
    ")\n",
    "merged = merged[ordered_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9061b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../cleaned_data/ECOM03_cleaned.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eeb533",
   "metadata": {},
   "source": [
    "## 16. Merge all data based on ```hhid```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "655bfd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking row counts...\n",
      "\n",
      "Checking hhid consistency...\n",
      "\n",
      "Consistency check complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# path storing cleaned data\n",
    "cleaned_path = '../cleaned_data'\n",
    "files = [f for f in os.listdir(cleaned_path) if f.endswith('.csv')]\n",
    "\n",
    "hhid_sets = {}\n",
    "row_counts = {}\n",
    "\n",
    "for file in files:\n",
    "    path = os.path.join(cleaned_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(path, encoding='utf-8-sig')\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to read {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if 'hhid' not in df.columns:\n",
    "        print(f\"[MISSING] 'hhid' column not found in {file}\")\n",
    "        continue\n",
    "\n",
    "    hhid_list = df['hhid'].astype(str).tolist()\n",
    "    hhid_sets[file] = set(hhid_list)\n",
    "    row_counts[file] = len(hhid_list)\n",
    "\n",
    "# 1. check rows num\n",
    "print(\"\\nChecking row counts...\")\n",
    "base_file, base_count = next(iter(row_counts.items()))\n",
    "for file, count in row_counts.items():\n",
    "    if count != base_count:\n",
    "        print(f\"[ROW COUNT MISMATCH] {file}: {count} rows (expected {base_count})\")\n",
    "\n",
    "# 2. check hhid\n",
    "print(\"\\nChecking hhid consistency...\")\n",
    "base_hhids = hhid_sets[base_file]\n",
    "for file, hhids in hhid_sets.items():\n",
    "    if hhids != base_hhids:\n",
    "        missing = base_hhids - hhids\n",
    "        extra = hhids - base_hhids\n",
    "        print(f\"[HHID MISMATCH] {file}:\")\n",
    "        if missing:\n",
    "            print(f\"  ↳ Missing hhids (vs base): {sorted(list(missing))[:5]}...\")\n",
    "        if extra:\n",
    "            print(f\"  ↳ Extra hhids (not in base): {sorted(list(extra))[:5]}...\")\n",
    "\n",
    "print(\"\\nConsistency check complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7404d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging: AUTOIDH_cleaned.csv (3 columns)\n",
      "Merging: CONSUMO5_cleaned.csv (6 columns)\n",
      "Merging: ECOM02_cleaned.csv (9 columns)\n",
      "Merging: ECOM03_cleaned.csv (17 columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging: ECV01H01_cleaned.csv (29 columns)\n",
      "Merging: ECV02H01_cleaned.csv (22 columns)\n",
      "Merging: ECV09P05_cleaned.csv (15 columns)\n",
      "Merging: ECV11P10_cleaned.csv (6 columns)\n",
      "Merging: ECV17E14_cleaned.csv (39 columns)\n",
      "Merging: ECV18N15_cleaned.csv (3 columns)\n",
      "Merging: ECV21A16_cleaned.csv (2 columns)\n",
      "Merging: ECV28A16_cleaned.csv (27 columns)\n",
      "Merging: ECV31A16_cleaned.csv (12 columns)\n",
      "\n",
      "Final merged dataset saved to: ../merged_data\\guatemala_household_data.csv\n",
      "Final shape: 7276 rows, 182 columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_path = '../cleaned_data'\n",
    "merged_path = '../merged_data'\n",
    "all_files = [f for f in os.listdir(cleaned_path) if f.endswith('.csv')]\n",
    "\n",
    "merge_files = [f for f in all_files if f != 'geo_info_per_household.csv']\n",
    "\n",
    "# main table: HOGARES_cleaned.csv\n",
    "merge_files_sorted = ['HOGARES_cleaned.csv'] + [f for f in merge_files if f != 'HOGARES_cleaned.csv']\n",
    "main_df = pd.read_csv(os.path.join(cleaned_path, merge_files_sorted[0]), encoding='utf-8-sig')\n",
    "\n",
    "# all left joint\n",
    "for file in merge_files_sorted[1:]:\n",
    "    path = os.path.join(cleaned_path, file)\n",
    "    df = pd.read_csv(path, encoding='utf-8-sig')\n",
    "    print(f\"Merging: {file} ({df.shape[1]} columns)\")\n",
    "    main_df = main_df.merge(df, on='hhid', how='left')\n",
    "\n",
    "output_path = os.path.join(merged_path, 'guatemala_household_data.csv')\n",
    "main_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nFinal merged dataset saved to: {output_path}\")\n",
    "print(f\"Final shape: {main_df.shape[0]} rows, {main_df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfa44ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in the merged dataset.\n"
     ]
    }
   ],
   "source": [
    "# check missing\n",
    "merged_path = '../merged_data/guatemala_household_data.csv'\n",
    "merged_df = pd.read_csv(merged_path, encoding='utf-8-sig')\n",
    "\n",
    "total_missing = merged_df.isnull().sum().sum()\n",
    "if total_missing == 0:\n",
    "    print(\"No missing values in the merged dataset.\")\n",
    "else:\n",
    "    print(f\"Total missing values in dataset: {total_missing}\")\n",
    "    print(\"\\n Missing value count per column (non-zero only):\")\n",
    "    missing_per_column = merged_df.isnull().sum()\n",
    "    print(missing_per_column[missing_per_column > 0].sort_values(ascending=False))\n",
    "\n",
    "    print(\"\\nTop 10 columns with most missing values:\")\n",
    "    print(missing_per_column.sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779029b6",
   "metadata": {},
   "source": [
    "## 17. Add ```headcount_adjusted_hh_wgt```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6135000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create headcount-adjusted weight col\n",
    "merged_df['headcount_adjusted_hh_wgt'] = merged_df['hh_wgt'] * merged_df['hh_size']\n",
    "merged_df.to_csv(merged_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1afc3",
   "metadata": {},
   "source": [
    "## 18. Generate ```country_name_metadata.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ffc2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_data_type(series):\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        return 'numeric'\n",
    "    else:\n",
    "        return 'categorical'\n",
    "\n",
    "variable_info = pd.DataFrame({\n",
    "    'variable_name': df.columns,\n",
    "    'data_type': [infer_data_type(df[col]) for col in df.columns]\n",
    "})\n",
    "\n",
    "variable_info.to_csv('../metadata/final_variable_types.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d946bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_types_df = pd.read_csv('../metadata/final_variable_types.csv', encoding='utf-8-sig')\n",
    "metadata_df = pd.read_csv('../metadata/guatemala_metadata.csv', encoding='utf-8-sig').copy()\n",
    "\n",
    "var_types_df['variable_name'] = var_types_df['variable_name'].str.strip().str.lower()\n",
    "metadata_df['variable_name'] = metadata_df['variable_name'].str.strip().str.lower()\n",
    "\n",
    "merged_df = var_types_df.merge(metadata_df, on='variable_name', how='left')\n",
    "\n",
    "merged_df.to_csv('../metadata/final_variable_types.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3a94852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amend geeographic indicator\n",
    "metadata_df['geographic_indicator'] = metadata_df['geographic_indicator'].map({'no' : False, 'yes' : True})\n",
    "\n",
    "# Formatting\n",
    "metadata_df.drop(metadata_df[metadata_df['variable_name'] == 'agreg3'].index, inplace=True)\n",
    "metadata_df['variable_name'] = metadata_df['variable_name'].replace('thogar', 'hh_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d241e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.to_csv('../metadata/guatemala_metadata_final.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smrintenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
